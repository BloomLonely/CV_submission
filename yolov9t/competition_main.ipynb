{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e01bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_augmentation import augment_train_images\n",
    "iterations = [1, 10]\n",
    "for i in range(iterations[0], iterations[1]+1):\n",
    "    augment_train_images('Datasets/Airplane', iter_num=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a22a04-1665-4ea8-b1a4-e0172ce1a30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=250422_191025_Train, mode=train, model=models/YOLOv9t/yolov9t.yaml, data=Datasets/Airplane/data_iter_01.yaml, epochs=20, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=tmp, name=yolov9t_Airplane_Iter_1, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.9, weight_decay=0.0001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp\\250422_191025_models\\YOLOv9t\\yolov9t_Airplane_Iter_1\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567187  ultralytics.nn.modules.head.Detect           [1, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,603 parameters, 2,005,587 gradients, 7.8 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir tmp\\250422_191025_models\\YOLOv9t\\yolov9t_Airplane_Iter_1', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning Datasets\\Airplane\\labels.cache... 480 images, 0 backgrounds, 0 corrupt: 100%|██████████| 480/480 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning Datasets\\Airplane\\labels... 160 images, 0 backgrounds, 0 corrupt: 100%|██████████| 160/160 [00:00<00:00, 425.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: Datasets\\Airplane\\labels.cache\n",
      "Plotting labels to tmp\\250422_191025_models\\YOLOv9t\\yolov9t_Airplane_Iter_1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.0001), 227 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mtmp\\250422_191025_models\\YOLOv9t\\yolov9t_Airplane_Iter_1\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      5.03G      3.283      3.497      3.805         62        640: 100%|██████████| 30/30 [00:12<00:00,  2.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:02<00:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323    0.00252      0.375    0.00735     0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      5.63G      3.255       3.24      3.522         53        640: 100%|██████████| 30/30 [00:08<00:00,  3.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323    0.00235       0.35    0.00501    0.00111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      5.63G      3.065      3.067      3.385         58        640: 100%|██████████| 30/30 [00:08<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323    0.00746      0.189    0.00347   0.000691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      5.63G      2.916      3.022      3.268         43        640: 100%|██████████| 30/30 [00:08<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323    0.00854      0.102    0.00469    0.00129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      5.63G      2.769      2.978      3.145         59        640: 100%|██████████| 30/30 [00:08<00:00,  3.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323     0.0267      0.285     0.0122    0.00301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      5.63G      2.677      2.904      3.063         43        640: 100%|██████████| 30/30 [00:08<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323     0.0349      0.297     0.0182    0.00478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20      5.63G      2.579      2.863      2.986         64        640: 100%|██████████| 30/30 [00:08<00:00,  3.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323     0.0541      0.257     0.0256    0.00734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      5.63G      2.504      2.839      2.953         57        640: 100%|██████████| 30/30 [00:08<00:00,  3.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323     0.0617       0.18     0.0293    0.00826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      5.63G      2.437      2.807      2.867         33        640: 100%|██████████| 30/30 [00:08<00:00,  3.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323     0.0902      0.152     0.0506     0.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      5.63G      2.454      2.802      2.847         63        640: 100%|██████████| 30/30 [00:08<00:00,  3.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        160        323      0.111      0.146     0.0568     0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    }
   ],
   "source": [
    "from competition_utils import *\n",
    "\n",
    "# 제출 함수를 리스트로 정의 (submission_N_학번)\n",
    "# 깃허브에는 최대 3개 업로드 데모시 하이퍼파라미터 튜닝 후 1개만 제출\n",
    "#submission_functions = ['submission_1_2023110214', 'submission_2_2023110214', 'submission_3_2023110214']\n",
    "submission_functions = ['submission_yolov9t']\n",
    "for submission_function in submission_functions:\n",
    "    exec(f\"from {submission_function} import {submission_function}\")\n",
    "\n",
    "# 분석 방향에 따라 iteration 수 수정\n",
    "# 평가시에는 데모와 다른 스플릿 시드를 만들어 [1, 10]로 진행 예정\n",
    "iterations = [1, 3] \n",
    "\n",
    "# 'Crown Detection'는 예제 데이터셋, 데모 및 평가시에는 'CV_Competition'\n",
    "Dataset_Name = 'Airplane' \n",
    "\n",
    "# 결과를 모아 하나의 csv 파일에 저장\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Experiment Time', 'Iteration', 'Submission Function', \n",
    "    'IoU', 'Dice', 'Precision', 'Recall', 'Output Json Path',\n",
    "])\n",
    "csv_filename = f\"Evaluation_Results_{datetime.now().strftime('%y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "# 서로 다른 iteration, submission function으로 실험 진행\n",
    "for iteration in range(iterations[0], iterations[1]+1):\n",
    "    yaml_path = f'Datasets/{Dataset_Name}/data_iter_{iteration:02d}.yaml'\n",
    "    for submission_function in submission_functions:\n",
    "        ex_time = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "        output_json_path = f\"{ex_time}_{submission_function}_Iter_{iteration}_detection_results.json\"\n",
    "        globals()[submission_function](yaml_path, output_json_path)\n",
    "        labels_dir = f\"Datasets/{Dataset_Name}/labels\"  \n",
    "        vis_output_dir = f\"{ex_time}_visualization_results\"  \n",
    "        image_level_result_path =f\"{ex_time}_{submission_function}_Iter_{iteration}_image_level_results.json\"\n",
    "        stats = eval_and_vis(yaml_path, output_json_path, labels_dir, image_level_result_path, vis_output_dir, vis=False) # 분석 방향에 따라 vis=True 설정\n",
    "        new_row = {\n",
    "            'Experiment Time': ex_time,\n",
    "            'Iteration': iteration,\n",
    "            'Submission Function': submission_function,\n",
    "            'IoU': stats['IoU']['avg'],\n",
    "            'Dice': stats['Dice']['avg'],\n",
    "            'Precision': stats['Precision']['avg'],\n",
    "            'Recall': stats['Recall']['avg'],\n",
    "            'Output Json Path': output_json_path,\n",
    "        }\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        results_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42711cc-d6dc-49db-b7cd-d9ebc4a9f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일로 저장 완료: Evaluation_Results_250418_081601_agg.csv\n"
     ]
    }
   ],
   "source": [
    "# 분석 방향에 따라 전체 결과를 모아 평균-표준편차-통계테스트 결과 저장 \n",
    "\n",
    "keep_columns = ['Iteration','Submission Function']\n",
    "keep_measures = ['IoU','Dice','Precision','Recall']  \n",
    "\n",
    "reduction = 'Iteration'\n",
    "row = 'Measure Type'\n",
    "column = 'Submission Function'\n",
    "reference_column = 'submission_yolov9t'\n",
    "\n",
    "custom_fmt_template = '{mean_fmt} ± {std_fmt} {significance}'\n",
    "significance_levels = [0.1, 0.05, 0.01]\n",
    "decimal_places = 3\n",
    "transpose = True\n",
    "make_tables(csv_filename, keep_columns, keep_measures, reduction, row, column,  \n",
    "            reference_column, custom_fmt_template, significance_levels, decimal_places, transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f0a89-b0b6-4406-9500-24156dabcfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
